#!/usr/bin/env python3
"""Plot benchmark metrics from the exported CSV."""

from __future__ import annotations

import argparse
import csv
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple

import matplotlib.pyplot as plt

MetricSeries = Dict[str, List[Tuple[float, float]]]


SUPPORTED_METRICS = {
    "msg_per_sec": "Message throughput (msgs/s)",
    "approx_mb_per_sec": "Approx volume (MB/s)",
    "kafka_payload_mb_per_sec": "Kafka payload (MB/s)",
    "source_mb_per_sec": "Source throughput (MB/s)",
}


def load_series(csv_path: Path, metric: str) -> MetricSeries:
    series: MetricSeries = defaultdict(list)
    with csv_path.open("r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            target = row.get("target") or "unknown"
            try:
                rate = float(row.get("rate_mb") or 0)
                metric_value_raw = row.get(metric, "").strip()
                if metric_value_raw == "":
                    continue
                metric_value = float(metric_value_raw)
            except ValueError:
                continue

            series[target].append((rate, metric_value))

    for target in series:
        series[target].sort(key=lambda item: item[0])
    return series


def plot_series(series: MetricSeries, metric: str, output: Path | None) -> None:
    plt.figure(figsize=(8, 5))
    for target, values in sorted(series.items()):
        rates = [rate for rate, _ in values]
        metrics = [value for _, value in values]
        plt.plot(rates, metrics, marker="o", label=target)

    plt.xlabel("Configured rate (MB/s)")
    plt.ylabel(SUPPORTED_METRICS.get(metric, metric))
    plt.title(f"Benchmark {metric} curve")
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()

    if output:
        output.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output, dpi=200)
        print(f"Plot saved to {output}")
    else:
        plt.show()


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Plot benchmark metric curves from CSV"
    )
    parser.add_argument(
        "--csv",
        type=Path,
        default=Path("bench/results/benchmark_series.csv"),
        help="CSV file generated by export_bench_results.py",
    )
    parser.add_argument(
        "--metric",
        type=str,
        choices=sorted(SUPPORTED_METRICS.keys()),
        default="source_mb_per_sec",
        help="Metric column to plot",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="Optional path to save the plot as an image",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    data = load_series(args.csv, args.metric)
    if not data:
        raise SystemExit(f"No data found in {args.csv} for metric '{args.metric}'")

    plot_series(data, args.metric, args.output)


if __name__ == "__main__":
    main()
